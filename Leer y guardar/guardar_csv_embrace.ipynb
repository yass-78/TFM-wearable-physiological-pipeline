{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a0c9e-2868-49ce-86ee-160dac961bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Exporting signals in Empatica E4 format by parts\n",
    "#\n",
    "# Processes ONE subject from ~/TFM/all_data.pkl\n",
    "# (dict: subject_id -> list of blocks)\n",
    "# and exports CSV files following the Empatica E4 structure,\n",
    "# split by sensor and temporal parts.\n",
    "#\n",
    "# Output structure:\n",
    "# ~/TFM/step2_e4csv/<SUBJECT>/\n",
    "#   ├── EDA/  (part01.csv, part02.csv, ...)\n",
    "#   ├── TEMP/ (part01.csv, ...)\n",
    "#   ├── BVP/  (part01.csv, ...)\n",
    "#   ├── ACC/  (part01.csv, ...)\n",
    "#   ├── IBI/  (part01.csv, ...)\n",
    "#   ├── _manifest.csv\n",
    "#   └── _README_UNITS.txt\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import math\n",
    "import gc\n",
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# -------------------- Parameters --------------------\n",
    "# Input pickle with all subjects\n",
    "in_all = os.path.expanduser(\"~/TFM/all_data.pkl\")  # dict: patient_id -> list[blocks]\n",
    "\n",
    "# Output root directory\n",
    "out_root = os.path.expanduser(\"~/TFM/step2_e4csv\")\n",
    "\n",
    "# Target subject (if None, first one alphabetically)\n",
    "patient_id_target = \"CLIDEM22\"\n",
    "\n",
    "# Split rules (temporal gaps)\n",
    "gap_split_sec_uniform = 180  # 3 min (EDA/TEMP/BVP/ACC)\n",
    "gap_split_sec_ibi = 120      # 2 min between peaks (IBI)\n",
    "\n",
    "# Target sampling frequencies\n",
    "FS_TARGET_TEMP = 4           # TEMP: 1 Hz -> 4 Hz (interpolation)\n",
    "FS_TARGET_ACC = 32           # ACC: 64 Hz -> 32 Hz (antialias + resampling)\n",
    "\n",
    "# Sampling frequency tolerances\n",
    "FS_TOL_ABS = 0.01            # Hz\n",
    "FS_TOL_REL = 0.0025          # 0.25%\n",
    "\n",
    "\n",
    "# -------------------- Helper functions --------------------\n",
    "def final_timestamp(t0: float, n: int, fs: float) -> float:\n",
    "    # Last timestamp of a uniformly sampled block\n",
    "    return t0 + (n - 1) / fs\n",
    "\n",
    "\n",
    "def gap_epsilon(fs: float) -> float:\n",
    "    # Temporal jitter tolerance: |gap| <= 1/fs is considered continuous\n",
    "    if fs is None or (isinstance(fs, float) and (math.isnan(fs) or fs <= 0)):\n",
    "        return 0.0\n",
    "    return 1.0 / fs\n",
    "\n",
    "\n",
    "def same_fs(a: float, b: float,\n",
    "            tol_abs: float = FS_TOL_ABS,\n",
    "            tol_rel: float = FS_TOL_REL) -> bool:\n",
    "    # Compare sampling frequencies with absolute and relative tolerance\n",
    "    if a is None or b is None:\n",
    "        return False\n",
    "    if (isinstance(a, float) and math.isnan(a)) or (isinstance(b, float) and math.isnan(b)):\n",
    "        return False\n",
    "    diff = abs(a - b)\n",
    "    thr = max(tol_abs, tol_rel * max(abs(a), abs(b)))\n",
    "    return diff <= thr\n",
    "\n",
    "\n",
    "def resample_signal(values: np.ndarray, fs_orig: float, fs_target: float) -> np.ndarray:\n",
    "    # Linear interpolation resampling\n",
    "    values = np.asarray(values, dtype=float)\n",
    "    if fs_orig <= 0 or fs_target <= 0 or values.size <= 1:\n",
    "        return values\n",
    "\n",
    "    t_orig = np.arange(values.size) / fs_orig\n",
    "    t_target = np.arange(0, t_orig[-1] + 1e-12, 1.0 / fs_target)\n",
    "    return np.interp(t_target, t_orig, values).astype(float)\n",
    "\n",
    "\n",
    "def fill_na_edges(x: np.ndarray) -> np.ndarray:\n",
    "    # Fill NaNs at the beginning and end with nearest valid values\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if not np.isnan(x).any():\n",
    "        return x\n",
    "\n",
    "    if np.isnan(x[0]):\n",
    "        first_ok = np.where(~np.isnan(x))[0]\n",
    "        if first_ok.size:\n",
    "            x[:first_ok[0] + 1] = x[first_ok[0]]\n",
    "\n",
    "    if np.isnan(x[-1]):\n",
    "        last_ok = np.where(~np.isnan(x))[0]\n",
    "        if last_ok.size:\n",
    "            x[last_ok[-1]:] = x[last_ok[-1]]\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def lowpass_ma_centered(values: np.ndarray, k: int) -> np.ndarray:\n",
    "    # Simple centered moving-average low-pass filter\n",
    "    values = np.asarray(values, dtype=float)\n",
    "    k = max(1, int(round(k)))\n",
    "    if k % 2 == 0:\n",
    "        k += 1\n",
    "    if k == 1 or values.size < k:\n",
    "        return values\n",
    "\n",
    "    kernel = np.ones(k, dtype=float) / k\n",
    "    y = np.convolve(values, kernel, mode=\"same\")\n",
    "    return fill_na_edges(y)\n",
    "\n",
    "\n",
    "def is_integer_ratio(fs_orig: float, fs_target: float, tol: float = 1e-6) -> bool:\n",
    "    # Check if fs_orig / fs_target is (approximately) an integer\n",
    "    if fs_orig is None or fs_target is None or fs_target == 0:\n",
    "        return False\n",
    "    r = fs_orig / fs_target\n",
    "    return abs(r - round(r)) < tol\n",
    "\n",
    "\n",
    "def resample_with_antialias(values: np.ndarray,\n",
    "                            fs_orig: float,\n",
    "                            fs_target: float) -> np.ndarray:\n",
    "    # Resampling with basic antialiasing (used for ACC)\n",
    "    values = np.asarray(values, dtype=float)\n",
    "    if fs_orig <= 0 or fs_target <= 0 or values.size <= 1:\n",
    "        return values\n",
    "\n",
    "    if abs(fs_orig - fs_target) < 1e-12:\n",
    "        return values\n",
    "\n",
    "    if fs_orig < fs_target:\n",
    "        return resample_signal(values, fs_orig, fs_target)\n",
    "\n",
    "    r = fs_orig / fs_target\n",
    "    if is_integer_ratio(fs_orig, fs_target):\n",
    "        k = int(round(r))\n",
    "        y = lowpass_ma_centered(values, k)\n",
    "        return y[::k]\n",
    "    else:\n",
    "        k = int(math.ceil(r))\n",
    "        y = lowpass_ma_centered(values, k)\n",
    "        return resample_signal(y, fs_orig, fs_target)\n",
    "\n",
    "\n",
    "def trim_overlap_samples(t_final_prev: float,\n",
    "                          t0_next: float,\n",
    "                          fs_next: float) -> int:\n",
    "    # Number of samples to drop when blocks overlap\n",
    "    if fs_next <= 0:\n",
    "        return 0\n",
    "    overlap_sec = t_final_prev - t0_next\n",
    "    if overlap_sec <= 0:\n",
    "        return 0\n",
    "    return max(0, int(math.floor(overlap_sec * fs_next) + 1))\n",
    "\n",
    "\n",
    "def format_hms(sec: float) -> str | None:\n",
    "    # Convert seconds to HH:MM:SS\n",
    "    if sec is None or (isinstance(sec, float) and math.isnan(sec)) or sec < 0:\n",
    "        return None\n",
    "    h = int(sec // 3600)\n",
    "    m = int((sec % 3600) // 60)\n",
    "    s = int(round(sec % 60))\n",
    "    return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
    "\n",
    "\n",
    "def epoch_to_iso(t0: float) -> str:\n",
    "    # Epoch seconds to ISO-8601 UTC\n",
    "    return datetime.fromtimestamp(float(t0), tz=timezone.utc).isoformat()\n",
    "\n",
    "\n",
    "# -------------------- E4 writers --------------------\n",
    "def ensure_dir(path: str) -> None:\n",
    "    # Create directory if needed\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "def write_signal_single(path: str,\n",
    "                        t0: float,\n",
    "                        fs: float,\n",
    "                        vals: np.ndarray) -> None:\n",
    "    # Write EDA / TEMP / BVP E4 format\n",
    "    ensure_dir(os.path.dirname(path))\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"{t0:.12f}\\n\")\n",
    "        f.write(f\"{fs:.12f}\\n\")\n",
    "        for v in np.asarray(vals, dtype=float):\n",
    "            f.write(\"NA\\n\" if np.isnan(v) else f\"{v}\\n\")\n",
    "\n",
    "\n",
    "def write_signal_acc(path: str,\n",
    "                     t0: float,\n",
    "                     fs: float,\n",
    "                     x: np.ndarray,\n",
    "                     y: np.ndarray,\n",
    "                     z: np.ndarray) -> None:\n",
    "    # Write ACC E4 format (3 axes)\n",
    "    ensure_dir(os.path.dirname(path))\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\",\".join([f\"{t0:.12f}\"] * 3) + \"\\n\")\n",
    "        f.write(\",\".join([f\"{fs:.12f}\"] * 3) + \"\\n\")\n",
    "        n = min(len(x), len(y), len(z))\n",
    "        for i in range(n):\n",
    "            def fmt(v):\n",
    "                return \"NA\" if np.isnan(v) else f\"{v}\"\n",
    "            f.write(f\"{fmt(x[i])},{fmt(y[i])},{fmt(z[i])}\\n\")\n",
    "\n",
    "\n",
    "def write_signal_ibi(path: str,\n",
    "                     t0: float,\n",
    "                     offsets: np.ndarray,\n",
    "                     ibis: np.ndarray) -> None:\n",
    "    # Write IBI E4 format (event-based)\n",
    "    ensure_dir(os.path.dirname(path))\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"{t0:.6f},IBI\\n\")\n",
    "        for o, i in zip(offsets, ibis):\n",
    "            f.write(f\"{o:.10f},{i:.10f}\\n\")\n",
    "\n",
    "\n",
    "# -------------------- Segmentation structures --------------------\n",
    "@dataclass\n",
    "class Part1D:\n",
    "    t0: float\n",
    "    fs: float\n",
    "    vals: np.ndarray\n",
    "    n_blocks: int\n",
    "    splits: str\n",
    "    trimmed: int\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PartACC:\n",
    "    t0: float\n",
    "    fs: float\n",
    "    x: np.ndarray\n",
    "    y: np.ndarray\n",
    "    z: np.ndarray\n",
    "    n_blocks: int\n",
    "    splits: str\n",
    "    trimmed: int\n",
    "\n",
    "\n",
    "# -------------------- Segmentation logic --------------------\n",
    "def segment_items_1d(items,\n",
    "                     gap_split_sec: float,\n",
    "                     check_fs: bool) -> list[Part1D]:\n",
    "    # Segment uniformly sampled 1D signals\n",
    "    if not items:\n",
    "        return []\n",
    "\n",
    "    items = sorted(items, key=lambda d: d[\"t0\"])\n",
    "    parts = []\n",
    "\n",
    "    cur_vals = None\n",
    "    cur_t0 = None\n",
    "    cur_fs = None\n",
    "    cur_blocks = 0\n",
    "    split_reasons = []\n",
    "    total_trim = 0\n",
    "\n",
    "    def flush():\n",
    "        nonlocal cur_vals, cur_t0, cur_fs, cur_blocks, split_reasons, total_trim\n",
    "        if cur_vals is None:\n",
    "            return\n",
    "        parts.append(\n",
    "            Part1D(\n",
    "                t0=cur_t0,\n",
    "                fs=cur_fs,\n",
    "                vals=np.asarray(cur_vals),\n",
    "                n_blocks=cur_blocks,\n",
    "                splits=\" | \".join(split_reasons),\n",
    "                trimmed=total_trim,\n",
    "            )\n",
    "        )\n",
    "        cur_vals = None\n",
    "        cur_t0 = None\n",
    "        cur_fs = None\n",
    "        cur_blocks = 0\n",
    "        split_reasons = []\n",
    "        total_trim = 0\n",
    "\n",
    "    for it in items:\n",
    "        t0, fs, vals = it[\"t0\"], it[\"fs\"], np.asarray(it[\"vals\"])\n",
    "\n",
    "        if cur_vals is None:\n",
    "            cur_t0, cur_fs = t0, fs\n",
    "            cur_vals = vals\n",
    "            cur_blocks = 1\n",
    "            continue\n",
    "\n",
    "        if check_fs and not same_fs(cur_fs, fs):\n",
    "            split_reasons.append(\"fs_change\")\n",
    "            flush()\n",
    "            cur_t0, cur_fs = t0, fs\n",
    "            cur_vals = vals\n",
    "            cur_blocks = 1\n",
    "            continue\n",
    "\n",
    "        t_final_prev = final_timestamp(cur_t0, len(cur_vals), cur_fs)\n",
    "        gap = t0 - t_final_prev\n",
    "        eps = gap_epsilon(cur_fs)\n",
    "\n",
    "        if gap > gap_split_sec:\n",
    "            split_reasons.append(f\"gap>{int(gap_split_sec)}s\")\n",
    "            flush()\n",
    "            cur_t0, cur_fs = t0, fs\n",
    "            cur_vals = vals\n",
    "            cur_blocks = 1\n",
    "        elif gap < -eps:\n",
    "            drop = trim_overlap_samples(t_final_prev, t0, fs)\n",
    "            total_trim += drop\n",
    "            if drop < len(vals):\n",
    "                cur_vals = np.concatenate([cur_vals, vals[drop:]])\n",
    "                cur_blocks += 1\n",
    "        else:\n",
    "            cur_vals = np.concatenate([cur_vals, vals])\n",
    "            cur_blocks += 1\n",
    "\n",
    "    flush()\n",
    "    return parts\n",
    "\n",
    "\n",
    "def segment_items_acc(items,\n",
    "                      gap_split_sec: float) -> list[PartACC]:\n",
    "    # Segment ACC signals (already resampled to target fs)\n",
    "    if not items:\n",
    "        return []\n",
    "\n",
    "    items = sorted(items, key=lambda d: d[\"t0\"])\n",
    "    parts = []\n",
    "\n",
    "    cur_x = cur_y = cur_z = None\n",
    "    cur_t0 = None\n",
    "    cur_fs = FS_TARGET_ACC\n",
    "    cur_blocks = 0\n",
    "    split_reasons = []\n",
    "    total_trim = 0\n",
    "\n",
    "    def flush():\n",
    "        nonlocal cur_x, cur_y, cur_z, cur_t0, cur_blocks, split_reasons, total_trim\n",
    "        if cur_x is None:\n",
    "            return\n",
    "        parts.append(\n",
    "            PartACC(\n",
    "                t0=cur_t0,\n",
    "                fs=cur_fs,\n",
    "                x=np.asarray(cur_x),\n",
    "                y=np.asarray(cur_y),\n",
    "                z=np.asarray(cur_z),\n",
    "                n_blocks=cur_blocks,\n",
    "                splits=\" | \".join(split_reasons),\n",
    "                trimmed=total_trim,\n",
    "            )\n",
    "        )\n",
    "        cur_x = cur_y = cur_z = None\n",
    "        cur_t0 = None\n",
    "        cur_blocks = 0\n",
    "        split_reasons = []\n",
    "        total_trim = 0\n",
    "\n",
    "    for it in items:\n",
    "        t0 = it[\"t0\"]\n",
    "        x, y, z = it[\"x\"], it[\"y\"], it[\"z\"]\n",
    "\n",
    "        if cur_x is None:\n",
    "            cur_t0 = t0\n",
    "            cur_x, cur_y, cur_z = x, y, z\n",
    "            cur_blocks = 1\n",
    "            continue\n",
    "\n",
    "        t_final_prev = final_timestamp(cur_t0, len(cur_x), cur_fs)\n",
    "        gap = t0 - t_final_prev\n",
    "        eps = gap_epsilon(cur_fs)\n",
    "\n",
    "        if gap > gap_split_sec:\n",
    "            split_reasons.append(f\"gap>{int(gap_split_sec)}s\")\n",
    "            flush()\n",
    "            cur_t0 = t0\n",
    "            cur_x, cur_y, cur_z = x, y, z\n",
    "            cur_blocks = 1\n",
    "        elif gap < -eps:\n",
    "            drop = trim_overlap_samples(t_final_prev, t0, cur_fs)\n",
    "            total_trim += drop\n",
    "            if drop < len(x):\n",
    "                cur_x = np.concatenate([cur_x, x[drop:]])\n",
    "                cur_y = np.concatenate([cur_y, y[drop:]])\n",
    "                cur_z = np.concatenate([cur_z, z[drop:]])\n",
    "                cur_blocks += 1\n",
    "        else:\n",
    "            cur_x = np.concatenate([cur_x, x])\n",
    "            cur_y = np.concatenate([cur_y, y])\n",
    "            cur_z = np.concatenate([cur_z, z])\n",
    "            cur_blocks += 1\n",
    "\n",
    "    flush()\n",
    "    return parts\n",
    "\n",
    "\n",
    "# -------------------- Load data and select subject --------------------\n",
    "with open(in_all, \"rb\") as f:\n",
    "    all_data = pickle.load(f)\n",
    "\n",
    "if not isinstance(all_data, dict) or not all_data:\n",
    "    raise ValueError(\"all_data must be a non-empty dict\")\n",
    "\n",
    "patients = sorted(all_data.keys())\n",
    "patient_id = patients[0] if patient_id_target is None else patient_id_target\n",
    "\n",
    "if patient_id not in all_data:\n",
    "    raise ValueError(f\"Subject not found: {patient_id}\")\n",
    "\n",
    "blocks = all_data[patient_id]\n",
    "if not blocks:\n",
    "    raise ValueError(\"Selected subject has no data blocks\")\n",
    "\n",
    "# Output directories\n",
    "ensure_dir(out_root)\n",
    "pat_dir = os.path.join(out_root, patient_id)\n",
    "ensure_dir(pat_dir)\n",
    "for s in [\"EDA\", \"TEMP\", \"BVP\", \"ACC\", \"IBI\"]:\n",
    "    ensure_dir(os.path.join(pat_dir, s))\n",
    "\n",
    "manifest_rows = []\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# EDA\n",
    "# ============================================================\n",
    "eda_items = []\n",
    "for b in blocks:\n",
    "    eda = b.get(\"eda\")\n",
    "    if eda and eda.get(\"values\"):\n",
    "        t0 = float(eda[\"timestampStart\"]) / 1e6\n",
    "        fs = float(eda[\"samplingFrequency\"])\n",
    "        eda_items.append({\"t0\": t0, \"fs\": fs, \"vals\": eda[\"values\"]})\n",
    "\n",
    "for i, p in enumerate(segment_items_1d(eda_items,\n",
    "                                       gap_split_sec_uniform,\n",
    "                                       check_fs=True), 1):\n",
    "    fname = os.path.join(\"EDA\", f\"part{i:02d}.csv\")\n",
    "    write_signal_single(os.path.join(pat_dir, fname), p.t0, p.fs, p.vals)\n",
    "    dur = len(p.vals) / p.fs\n",
    "    manifest_rows.append({\n",
    "        \"sensor\": \"EDA\",\n",
    "        \"part\": i,\n",
    "        \"filename\": fname,\n",
    "        \"t0_epoch\": p.t0,\n",
    "        \"t0_iso\": epoch_to_iso(p.t0),\n",
    "        \"fs\": p.fs,\n",
    "        \"n\": len(p.vals),\n",
    "        \"duration_sec\": dur,\n",
    "        \"duration_hms\": format_hms(dur),\n",
    "        \"n_blocks\": p.n_blocks,\n",
    "        \"splits\": p.splits,\n",
    "        \"overlap_trim_samples\": p.trimmed,\n",
    "    })\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TEMP\n",
    "# ============================================================\n",
    "temp_items = []\n",
    "for b in blocks:\n",
    "    t = b.get(\"temperature\")\n",
    "    if t and t.get(\"values\"):\n",
    "        t0 = float(t[\"timestampStart\"]) / 1e6\n",
    "        fs_o = float(t[\"samplingFrequency\"])\n",
    "        vals = np.asarray(t[\"values\"], dtype=float)\n",
    "        if abs(fs_o - FS_TARGET_TEMP) < 1e-12 or math.isnan(fs_o):\n",
    "            vals_rs = vals\n",
    "        else:\n",
    "            vals_rs = resample_signal(vals, fs_o, FS_TARGET_TEMP)\n",
    "        temp_items.append({\"t0\": t0, \"fs\": FS_TARGET_TEMP, \"vals\": vals_rs})\n",
    "\n",
    "for i, p in enumerate(segment_items_1d(temp_items,\n",
    "                                       gap_split_sec_uniform,\n",
    "                                       check_fs=False), 1):\n",
    "    fname = os.path.join(\"TEMP\", f\"part{i:02d}.csv\")\n",
    "    write_signal_single(os.path.join(pat_dir, fname), p.t0, p.fs, p.vals)\n",
    "    dur = len(p.vals) / p.fs\n",
    "    manifest_rows.append({\n",
    "        \"sensor\": \"TEMP\",\n",
    "        \"part\": i,\n",
    "        \"filename\": fname,\n",
    "        \"t0_epoch\": p.t0,\n",
    "        \"t0_iso\": epoch_to_iso(p.t0),\n",
    "        \"fs\": p.fs,\n",
    "        \"n\": len(p.vals),\n",
    "        \"duration_sec\": dur,\n",
    "        \"duration_hms\": format_hms(dur),\n",
    "        \"n_blocks\": p.n_blocks,\n",
    "        \"splits\": p.splits,\n",
    "        \"overlap_trim_samples\": p.trimmed,\n",
    "    })\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# BVP\n",
    "# ============================================================\n",
    "bvp_items = []\n",
    "for b in blocks:\n",
    "    bvp = b.get(\"bvp\")\n",
    "    if bvp and bvp.get(\"values\"):\n",
    "        t0 = float(bvp[\"timestampStart\"]) / 1e6\n",
    "        fs = float(bvp[\"samplingFrequency\"])\n",
    "        bvp_items.append({\"t0\": t0, \"fs\": fs, \"vals\": bvp[\"values\"]})\n",
    "\n",
    "for i, p in enumerate(segment_items_1d(bvp_items,\n",
    "                                       gap_split_sec_uniform,\n",
    "                                       check_fs=True), 1):\n",
    "    fname = os.path.join(\"BVP\", f\"part{i:02d}.csv\")\n",
    "    write_signal_single(os.path.join(pat_dir, fname), p.t0, p.fs, p.vals)\n",
    "    dur = len(p.vals) / p.fs\n",
    "    manifest_rows.append({\n",
    "        \"sensor\": \"BVP\",\n",
    "        \"part\": i,\n",
    "        \"filename\": fname,\n",
    "        \"t0_epoch\": p.t0,\n",
    "        \"t0_iso\": epoch_to_iso(p.t0),\n",
    "        \"fs\": p.fs,\n",
    "        \"n\": len(p.vals),\n",
    "        \"duration_sec\": dur,\n",
    "        \"duration_hms\": format_hms(dur),\n",
    "        \"n_blocks\": p.n_blocks,\n",
    "        \"splits\": p.splits,\n",
    "        \"overlap_trim_samples\": p.trimmed,\n",
    "    })\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ACC\n",
    "# ============================================================\n",
    "acc_items = []\n",
    "for b in blocks:\n",
    "    acc = b.get(\"accelerometer\")\n",
    "    if not acc:\n",
    "        continue\n",
    "\n",
    "    imu = acc.get(\"imuParams\", {}) or {}\n",
    "    try:\n",
    "        factor = ((float(imu[\"physicalMax\"]) - float(imu[\"physicalMin\"])) /\n",
    "                  (float(imu[\"digitalMax\"]) - float(imu[\"digitalMin\"])))\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    fs_o = float(acc.get(\"samplingFrequency\", float(\"nan\")))\n",
    "    t0 = float(acc.get(\"timestampStart\")) / 1e6\n",
    "\n",
    "    x = np.asarray(acc.get(\"x\", []), dtype=float) * factor * 64.0\n",
    "    y = np.asarray(acc.get(\"y\", []), dtype=float) * factor * 64.0\n",
    "    z = np.asarray(acc.get(\"z\", []), dtype=float) * factor * 64.0\n",
    "    if not len(x):\n",
    "        continue\n",
    "\n",
    "    if not math.isnan(fs_o) and abs(fs_o - FS_TARGET_ACC) > 1e-12:\n",
    "        x = resample_with_antialias(x, fs_o, FS_TARGET_ACC)\n",
    "        y = resample_with_antialias(y, fs_o, FS_TARGET_ACC)\n",
    "        z = resample_with_antialias(z, fs_o, FS_TARGET_ACC)\n",
    "\n",
    "    n = min(len(x), len(y), len(z))\n",
    "    acc_items.append({\"t0\": t0, \"x\": x[:n], \"y\": y[:n], \"z\": z[:n]})\n",
    "\n",
    "for i, p in enumerate(segment_items_acc(acc_items,\n",
    "                                        gap_split_sec_uniform), 1):\n",
    "    fname = os.path.join(\"ACC\", f\"part{i:02d}.csv\")\n",
    "    write_signal_acc(os.path.join(pat_dir, fname),\n",
    "                     p.t0, p.fs, p.x, p.y, p.z)\n",
    "    dur = len(p.x) / p.fs\n",
    "    manifest_rows.append({\n",
    "        \"sensor\": \"ACC\",\n",
    "        \"part\": i,\n",
    "        \"filename\": fname,\n",
    "        \"t0_epoch\": p.t0,\n",
    "        \"t0_iso\": epoch_to_iso(p.t0),\n",
    "        \"fs\": p.fs,\n",
    "        \"n\": len(p.x),\n",
    "        \"duration_sec\": dur,\n",
    "        \"duration_hms\": format_hms(dur),\n",
    "        \"n_blocks\": p.n_blocks,\n",
    "        \"splits\": p.splits,\n",
    "        \"overlap_trim_samples\": p.trimmed,\n",
    "    })\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# IBI\n",
    "# ============================================================\n",
    "peaks = []\n",
    "for b in blocks:\n",
    "    sp = b.get(\"systolicPeaks\")\n",
    "    if sp and sp.get(\"peaksTimeNanos\"):\n",
    "        peaks.extend([float(x) / 1e9 for x in sp[\"peaksTimeNanos\"]])\n",
    "\n",
    "peaks = np.unique(np.asarray(peaks))\n",
    "peaks.sort()\n",
    "\n",
    "if len(peaks) > 1:\n",
    "    gaps = np.diff(peaks)\n",
    "    cut_idx = np.where(gaps > gap_split_sec_ibi)[0]\n",
    "    starts = np.r_[0, cut_idx + 1]\n",
    "    ends = np.r_[cut_idx, len(peaks) - 1]\n",
    "\n",
    "    part = 0\n",
    "    for s, e in zip(starts, ends):\n",
    "        idx = np.arange(s, e + 1)\n",
    "        if len(idx) <= 1:\n",
    "            continue\n",
    "        part += 1\n",
    "        pk = peaks[idx]\n",
    "        t0 = pk[0]\n",
    "        offsets = pk[1:] - t0\n",
    "        ibis = np.diff(pk)\n",
    "\n",
    "        fname = os.path.join(\"IBI\", f\"part{part:02d}.csv\")\n",
    "        write_signal_ibi(os.path.join(pat_dir, fname),\n",
    "                         t0, offsets, ibis)\n",
    "\n",
    "        dur = offsets.max() if len(offsets) else 0.0\n",
    "        manifest_rows.append({\n",
    "            \"sensor\": \"IBI\",\n",
    "            \"part\": part,\n",
    "            \"filename\": fname,\n",
    "            \"t0_epoch\": t0,\n",
    "            \"t0_iso\": epoch_to_iso(t0),\n",
    "            \"fs\": np.nan,\n",
    "            \"n\": len(ibis),\n",
    "            \"duration_sec\": dur,\n",
    "            \"duration_hms\": format_hms(dur),\n",
    "            \"n_blocks\": np.nan,\n",
    "            \"splits\": \"\" if part == 1 else f\"gap>{gap_split_sec_ibi}s\",\n",
    "            \"overlap_trim_samples\": np.nan,\n",
    "        })\n",
    "\n",
    "\n",
    "# -------------------- Save manifest and README --------------------\n",
    "manifest = pd.DataFrame(manifest_rows)\n",
    "manifest.to_csv(os.path.join(pat_dir, \"_manifest.csv\"), index=False)\n",
    "\n",
    "readme_txt = \"\\n\".join([\n",
    "    \"Units per sensor:\",\n",
    "    \"- EDA: microSiemens (µS), no resampling.\",\n",
    "    \"- TEMP: Celsius (°C), resampled 1 Hz -> 4 Hz (linear interpolation).\",\n",
    "    \"- BVP: relative PPG units, no resampling.\",\n",
    "    \"- ACC: g×64 units, resampled 64 Hz -> 32 Hz with antialiasing.\",\n",
    "    \"- IBI: seconds, event-based.\",\n",
    "    \"\",\n",
    "    \"Segmentation rules:\",\n",
    "    f\"- EDA/TEMP/BVP/ACC: new part if gap > {gap_split_sec_uniform} s.\",\n",
    "    f\"- IBI: new part if inter-peak gap > {gap_split_sec_ibi} s.\",\n",
    "    \"\",\n",
    "    \"Tolerances:\",\n",
    "    \"- Sampling rate considered equal if |Δfs| <= max(0.01 Hz, 0.25%).\",\n",
    "    \"- Gaps <= 1/fs are treated as continuous.\",\n",
    "])\n",
    "\n",
    "with open(os.path.join(pat_dir, \"_README_UNITS.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(readme_txt + \"\\n\")\n",
    "\n",
    "print(f\"Export completed for subject {patient_id}\")\n",
    "print(f\"Output folder: {pat_dir}\")\n",
    "print(f\"Manifest file: {os.path.join(pat_dir, '_manifest.csv')}\")\n",
    "\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
