{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d192db-445d-426b-90dd-44964b0c986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SUBJECT PAIRING: EMBRACE PLUS vs EMPATICA (robust and optimal)\n",
    "#\n",
    "# - Embrace: uses _manifest.csv (t0_epoch + duration_sec | n/fs) or E4 parts (last non-empty)\n",
    "# - Normalizes subject IDs (CLIDEM011 ≡ CLIDEM11) before merging\n",
    "# - Global 1-to-1 matching (Hungarian algorithm if available, otherwise greedy)\n",
    "# - Cost = 1*|Δstart| + 0.5*|Δend| + 0.25*|Δduration| (ignores NA terms)\n",
    "# - Outputs: emparejamientos.csv, rangos_por_reloj.csv\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Configuration\n",
    "# ------------------------------------------------------------\n",
    "EMPATICA_ROOT = os.path.expanduser(\"~/Documents/EMPATICA_all\")\n",
    "EMBRACE_ROOT  = os.path.expanduser(\"~/TFM/step2_e4csv\")\n",
    "\n",
    "SENSORES_COMUNES  = [\"ACC\", \"EDA\", \"TEMP\", \"BVP\"]\n",
    "SENSORES_FALLBACK = [\"ACC\", \"EDA\", \"TEMP\", \"BVP\", \"HR\", \"IBI\"]\n",
    "\n",
    "DIR_SALIDA = os.path.expanduser(\"~/TFM/Emparejamiento\")\n",
    "SALIDA_EMPAREJAMIENTO = os.path.join(DIR_SALIDA, \"emparejamientos.csv\")\n",
    "SALIDA_RANGOS = os.path.join(DIR_SALIDA, \"rangos_por_reloj.csv\")\n",
    "os.makedirs(DIR_SALIDA, exist_ok=True)\n",
    "\n",
    "ALERTA_HORAS = 48  # QC threshold for large start-time differences\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# General helper functions\n",
    "# ------------------------------------------------------------\n",
    "def normalizar_sensor(sensor: str) -> str:\n",
    "    s = str(sensor).lower()\n",
    "    if \"acc\" in s:  return \"ACC\"\n",
    "    if \"eda\" in s:  return \"EDA\"\n",
    "    if \"temp\" in s: return \"TEMP\"\n",
    "    if \"bvp\" in s:  return \"BVP\"\n",
    "    if \"ibi\" in s:  return \"IBI\"\n",
    "    if \"hr\"  in s:  return \"HR\"\n",
    "    return str(sensor).upper()\n",
    "\n",
    "\n",
    "def epoch_to_dt_utc(x: float) -> datetime | None:\n",
    "    # Converts epoch (s or ms) to UTC datetime using basic heuristics\n",
    "    if x is None or (isinstance(x, float) and (math.isnan(x) or not math.isfinite(x))):\n",
    "        return None\n",
    "    try:\n",
    "        if x < 1e7:\n",
    "            return None\n",
    "        if x > 1e11:\n",
    "            x = x / 1000.0\n",
    "        return datetime.fromtimestamp(float(x), tz=timezone.utc)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def fmt_es(dt: datetime | None) -> str | None:\n",
    "    # Spanish-style datetime formatting\n",
    "    if dt is None:\n",
    "        return None\n",
    "    return dt.astimezone(timezone.utc).strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "\n",
    "def normalize_clidem(x: str) -> str:\n",
    "    # CLIDEM011 -> CLIDEM11\n",
    "    x = str(x).strip().upper()\n",
    "    x = re.sub(r\"\\s+\", \"\", x)\n",
    "    m = re.match(r\"^([A-Z]+)(\\d+)$\", x)\n",
    "    if not m:\n",
    "        return x\n",
    "    pref, num = m.group(1), m.group(2)\n",
    "    try:\n",
    "        num = str(int(num))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return pref + num\n",
    "\n",
    "\n",
    "def normalize_empatica_id(x: str) -> str:\n",
    "    return str(x).strip()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# EMPATICA: compute start/end time per subject\n",
    "# ------------------------------------------------------------\n",
    "def leer_epoch_inicio_empatica(csv_path: str) -> float | None:\n",
    "    try:\n",
    "        with open(csv_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            l1 = f.readline().strip()\n",
    "        if not l1:\n",
    "            return None\n",
    "        v = float(l1.split(\",\")[0])\n",
    "        if not math.isfinite(v) or v < 1e7:\n",
    "            return None\n",
    "        return v\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def leer_freq_empatica(csv_path: str) -> float | None:\n",
    "    try:\n",
    "        with open(csv_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            _ = f.readline()\n",
    "            l2 = f.readline().strip()\n",
    "        if not l2:\n",
    "            return None\n",
    "        fr = float(l2.split(\",\")[0])\n",
    "        if (not math.isfinite(fr)) or fr <= 0:\n",
    "            return None\n",
    "        return fr\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def nfilas_datos_empatica(csv_path: str) -> int | None:\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path, skiprows=2, header=None, usecols=[0])\n",
    "        return int(df.shape[0])\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def rango_paciente_empatica(dir_paciente: str) -> dict:\n",
    "    paciente = os.path.basename(dir_paciente)\n",
    "    cand = [os.path.join(dir_paciente, f\"{s}.csv\") for s in SENSORES_COMUNES]\n",
    "    cand = [p for p in cand if os.path.exists(p)]\n",
    "\n",
    "    if not cand:\n",
    "        return {\"paciente\": paciente, \"start_empatica\": None, \"end_empatica\": None}\n",
    "\n",
    "    inicios = []\n",
    "    finales = []\n",
    "    for f in cand:\n",
    "        st = leer_epoch_inicio_empatica(f)\n",
    "        fr = leer_freq_empatica(f)\n",
    "        if st is None or fr is None:\n",
    "            continue\n",
    "        n = nfilas_datos_empatica(f)\n",
    "        if n is None or n <= 0:\n",
    "            continue\n",
    "        en = st + (n - 1) / fr\n",
    "        inicios.append(st)\n",
    "        finales.append(en)\n",
    "\n",
    "    if not inicios or not finales:\n",
    "        return {\"paciente\": paciente, \"start_empatica\": None, \"end_empatica\": None}\n",
    "\n",
    "    start = epoch_to_dt_utc(min(inicios))\n",
    "    end   = epoch_to_dt_utc(max(finales))\n",
    "    return {\"paciente\": paciente, \"start_empatica\": start, \"end_empatica\": end}\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# EMBRACE: compute start/end time per subject (robust)\n",
    "# ------------------------------------------------------------\n",
    "def e4_times_from_file(csv_path: str) -> dict:\n",
    "    try:\n",
    "        with open(csv_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            l1 = f.readline().strip()\n",
    "            l2 = f.readline().strip()\n",
    "        st = float(l1.split(\",\")[0])\n",
    "        fr = float(l2.split(\",\")[0])\n",
    "        if (not math.isfinite(st)) or (not math.isfinite(fr)) or fr <= 0:\n",
    "            return {\"start\": None, \"end\": None, \"n\": None, \"st_epoch\": None, \"fr\": None}\n",
    "\n",
    "        try:\n",
    "            n = int(pd.read_csv(csv_path, skiprows=2, header=None, usecols=[0]).shape[0])\n",
    "        except Exception:\n",
    "            n = None\n",
    "\n",
    "        start_dt = epoch_to_dt_utc(st)\n",
    "        if n is None or n <= 0:\n",
    "            return {\"start\": start_dt, \"end\": None, \"n\": n, \"st_epoch\": st, \"fr\": fr}\n",
    "\n",
    "        end_dt = epoch_to_dt_utc(st + (n - 1) / fr)\n",
    "        return {\"start\": start_dt, \"end\": end_dt, \"n\": n, \"st_epoch\": st, \"fr\": fr}\n",
    "    except Exception:\n",
    "        return {\"start\": None, \"end\": None, \"n\": None, \"st_epoch\": None, \"fr\": None}\n",
    "\n",
    "\n",
    "def sensor_start_end_from_dir(dir_sensor: str) -> dict:\n",
    "    files = [os.path.join(dir_sensor, f) for f in os.listdir(dir_sensor) if f.lower().endswith(\".csv\")]\n",
    "    if not files:\n",
    "        return {\"start\": None, \"end\": None}\n",
    "    files.sort()\n",
    "\n",
    "    st = None\n",
    "    en = None\n",
    "\n",
    "    # First non-empty file\n",
    "    for f in files:\n",
    "        tf = e4_times_from_file(f)\n",
    "        if tf[\"start\"] is not None and tf[\"n\"] is not None and tf[\"n\"] > 0:\n",
    "            st = tf[\"start\"]\n",
    "            break\n",
    "\n",
    "    # Last non-empty file\n",
    "    for f in reversed(files):\n",
    "        tf = e4_times_from_file(f)\n",
    "        if tf[\"end\"] is not None and tf[\"n\"] is not None and tf[\"n\"] > 0:\n",
    "            en = tf[\"end\"]\n",
    "            break\n",
    "\n",
    "    return {\"start\": st, \"end\": en}\n",
    "\n",
    "\n",
    "def rango_paciente_embrace(path_paciente: str) -> dict:\n",
    "    paciente = os.path.basename(path_paciente)\n",
    "    manifest_path = os.path.join(path_paciente, \"_manifest.csv\")\n",
    "\n",
    "    # Primary source: manifest\n",
    "    if os.path.exists(manifest_path):\n",
    "        try:\n",
    "            man = pd.read_csv(manifest_path)\n",
    "            if \"sensor\" in man.columns:\n",
    "                man[\"sensor\"] = man[\"sensor\"].astype(str).map(normalizar_sensor)\n",
    "\n",
    "            man2 = man[man[\"sensor\"].isin(SENSORES_COMUNES)] if \"sensor\" in man.columns else man\n",
    "            if len(man2) > 0 and \"t0_epoch\" in man2.columns:\n",
    "                t0 = pd.to_numeric(man2[\"t0_epoch\"], errors=\"coerce\").to_numpy(dtype=float)\n",
    "\n",
    "                if \"duration_sec\" in man2.columns:\n",
    "                    dur = pd.to_numeric(man2[\"duration_sec\"], errors=\"coerce\").to_numpy(dtype=float)\n",
    "                    t_end = t0 + dur\n",
    "                elif \"fs\" in man2.columns and \"n\" in man2.columns:\n",
    "                    fs = pd.to_numeric(man2[\"fs\"], errors=\"coerce\").to_numpy(dtype=float)\n",
    "                    nn = pd.to_numeric(man2[\"n\"], errors=\"coerce\").to_numpy(dtype=float)\n",
    "                    t_end = t0 + (nn - 1) / fs\n",
    "                else:\n",
    "                    t_end = np.full_like(t0, np.nan)\n",
    "\n",
    "                starts = [epoch_to_dt_utc(x) for x in t0 if epoch_to_dt_utc(x) is not None]\n",
    "                ends   = [epoch_to_dt_utc(x) for x in t_end if epoch_to_dt_utc(x) is not None]\n",
    "\n",
    "                if starts or ends:\n",
    "                    return {\n",
    "                        \"paciente\": paciente,\n",
    "                        \"start_embrace\": min(starts) if starts else None,\n",
    "                        \"end_embrace\": max(ends) if ends else None\n",
    "                    }\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Fallback: derive from sensor folders\n",
    "    starts = []\n",
    "    ends = []\n",
    "    for s in SENSORES_FALLBACK:\n",
    "        d = os.path.join(path_paciente, s)\n",
    "        if not os.path.isdir(d):\n",
    "            continue\n",
    "        se = sensor_start_end_from_dir(d)\n",
    "        if se[\"start\"] is not None:\n",
    "            starts.append(se[\"start\"])\n",
    "        if se[\"end\"] is not None:\n",
    "            ends.append(se[\"end\"])\n",
    "\n",
    "    return {\n",
    "        \"paciente\": paciente,\n",
    "        \"start_embrace\": min(starts) if starts else None,\n",
    "        \"end_embrace\": max(ends) if ends else None\n",
    "    }\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Build summaries\n",
    "# ------------------------------------------------------------\n",
    "def list_dirs(root: str) -> list[str]:\n",
    "    if not os.path.isdir(root):\n",
    "        return []\n",
    "    return [os.path.join(root, d) for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))]\n",
    "\n",
    "\n",
    "dirs_empatica = list_dirs(EMPATICA_ROOT)\n",
    "empatica_df = pd.DataFrame([rango_paciente_empatica(d) for d in dirs_empatica])\n",
    "if not empatica_df.empty:\n",
    "    empatica_df[\"paciente\"] = empatica_df[\"paciente\"].map(normalize_empatica_id)\n",
    "    empatica_df = empatica_df.dropna(subset=[\"start_empatica\"])\n",
    "    empatica_df[\"duracion_empatica_h\"] = (\n",
    "        (empatica_df[\"end_empatica\"] - empatica_df[\"start_empatica\"]).dt.total_seconds() / 3600.0\n",
    "    )\n",
    "\n",
    "dirs_embrace = list_dirs(EMBRACE_ROOT)\n",
    "embrace_df = pd.DataFrame([rango_paciente_embrace(d) for d in dirs_embrace])\n",
    "if not embrace_df.empty:\n",
    "    embrace_df[\"paciente\"] = embrace_df[\"paciente\"].map(normalize_clidem)\n",
    "    embrace_df = embrace_df.dropna(subset=[\"start_embrace\"])\n",
    "    embrace_df[\"duracion_embrace_h\"] = (\n",
    "        (embrace_df[\"end_embrace\"] - embrace_df[\"start_embrace\"]).dt.total_seconds() / 3600.0\n",
    "    )\n",
    "\n",
    "print(f\"Subjects after normalization: Embrace={len(embrace_df)} | Empatica={len(empatica_df)}\")\n",
    "\n",
    "if len(embrace_df) == 0 or len(empatica_df) == 0:\n",
    "    raise RuntimeError(\"Insufficient subjects for pairing. Check input paths.\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# One-to-one matching using combined cost\n",
    "# ------------------------------------------------------------\n",
    "def hours_diff(a: datetime | None, b: datetime | None) -> float | None:\n",
    "    if a is None or b is None:\n",
    "        return None\n",
    "    return abs((a - b).total_seconds()) / 3600.0\n",
    "\n",
    "\n",
    "def pair_cost(se, ee, de, ss, es, ds, w_start=1.0, w_end=0.5, w_dur=0.25) -> float:\n",
    "    c_start = hours_diff(ss, se)\n",
    "    c_end = None if (ee is None or es is None) else hours_diff(es, ee)\n",
    "    c_dur = None if (de is None or ds is None or math.isnan(de) or math.isnan(ds)) else abs(ds - de)\n",
    "    return (w_start * (c_start or 0.0)\n",
    "            + w_end * (c_end or 0.0)\n",
    "            + w_dur * (c_dur or 0.0))\n",
    "\n",
    "\n",
    "E = embrace_df[[\"paciente\", \"start_embrace\", \"end_embrace\", \"duracion_embrace_h\"]].reset_index(drop=True)\n",
    "P = empatica_df[[\"paciente\", \"start_empatica\", \"end_empatica\", \"duracion_empatica_h\"]].reset_index(drop=True)\n",
    "\n",
    "C = np.zeros((len(E), len(P)), dtype=float)\n",
    "for i in range(len(E)):\n",
    "    for j in range(len(P)):\n",
    "        C[i, j] = pair_cost(\n",
    "            E.at[i, \"start_embrace\"], E.at[i, \"end_embrace\"], E.at[i, \"duracion_embrace_h\"],\n",
    "            P.at[j, \"start_empatica\"], P.at[j, \"end_empatica\"], P.at[j, \"duracion_empatica_h\"],\n",
    "        )\n",
    "\n",
    "\n",
    "def assign_optimal(C: np.ndarray) -> list[tuple[int, int]]:\n",
    "    try:\n",
    "        from scipy.optimize import linear_sum_assignment\n",
    "        r, c = linear_sum_assignment(C)\n",
    "        return list(zip(r.tolist(), c.tolist()))\n",
    "    except Exception:\n",
    "        used_i = np.zeros(C.shape[0], dtype=bool)\n",
    "        used_j = np.zeros(C.shape[1], dtype=bool)\n",
    "        pairs = []\n",
    "        while True:\n",
    "            Cmask = C.copy()\n",
    "            Cmask[used_i, :] = np.inf\n",
    "            Cmask[:, used_j] = np.inf\n",
    "            if not np.isfinite(Cmask).any():\n",
    "                break\n",
    "            i, j = np.unravel_index(np.argmin(Cmask), Cmask.shape)\n",
    "            used_i[i] = True\n",
    "            used_j[j] = True\n",
    "            pairs.append((i, j))\n",
    "        return pairs\n",
    "\n",
    "\n",
    "pairs = assign_optimal(C)\n",
    "\n",
    "\n",
    "def get_pair_row(i: int, j: int) -> dict:\n",
    "    return {\n",
    "        \"paciente_embrace\": E.at[i, \"paciente\"],\n",
    "        \"paciente_empatica\": P.at[j, \"paciente\"],\n",
    "        \"diferencia_inicio_horas\": hours_diff(P.at[j, \"start_empatica\"], E.at[i, \"start_embrace\"]),\n",
    "        \"diferencia_final_horas\": hours_diff(P.at[j, \"end_empatica\"], E.at[i, \"end_embrace\"]),\n",
    "        \"diferencia_duracion_horas\": abs(P.at[j, \"duracion_empatica_h\"] - E.at[i, \"duracion_embrace_h\"]),\n",
    "        \"start_embrace\": E.at[i, \"start_embrace\"],\n",
    "        \"end_embrace\": E.at[i, \"end_embrace\"],\n",
    "        \"start_empatica\": P.at[j, \"start_empatica\"],\n",
    "        \"end_empatica\": P.at[j, \"end_empatica\"],\n",
    "    }\n",
    "\n",
    "\n",
    "emparejamientos_final = pd.DataFrame([get_pair_row(i, j) for i, j in pairs])\n",
    "emparejamientos_final.to_csv(SALIDA_EMPAREJAMIENTO, index=False)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Export ranges per device\n",
    "# ------------------------------------------------------------\n",
    "rangos_embrace = embrace_df.copy()\n",
    "rangos_embrace[\"reloj\"] = \"Embrace\"\n",
    "rangos_embrace[\"start\"] = rangos_embrace[\"start_embrace\"].map(fmt_es)\n",
    "rangos_embrace[\"end\"]   = rangos_embrace[\"end_embrace\"].map(fmt_es)\n",
    "rangos_embrace = rangos_embrace[[\"reloj\", \"paciente\", \"start\", \"end\"]]\n",
    "\n",
    "rangos_empatica = empatica_df.copy()\n",
    "rangos_empatica[\"reloj\"] = \"Empatica\"\n",
    "rangos_empatica[\"start\"] = rangos_empatica[\"start_empatica\"].map(fmt_es)\n",
    "rangos_empatica[\"end\"]   = rangos_empatica[\"end_empatica\"].map(fmt_es)\n",
    "rangos_empatica = rangos_empatica[[\"reloj\", \"paciente\", \"start\", \"end\"]]\n",
    "\n",
    "rangos_por_reloj = pd.concat([rangos_embrace, rangos_empatica], ignore_index=True)\n",
    "rangos_por_reloj.to_csv(SALIDA_RANGOS, index=False)\n",
    "\n",
    "print(\"Pairing completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
